{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GESI.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-U8g90GiUhK",
        "outputId": "1eb3cade-532c-4063-987b-5cf7db0fa3b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#uploading the data file\n",
        "import pandas as pd\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#importing inbuild libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import sklearn\n",
        "import os\n",
        "import gc\n",
        "gc.enable()\n",
        "from operator import itemgetter\n",
        "from tqdm import tqdm\n",
        "from scipy import optimize\n",
        "from sklearn.metrics import mean_squared_error as MSE\n",
        "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
        "from sklearn.gaussian_process import kernels\n",
        "from sklearn.base import BaseEstimator, RegressorMixin\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.linear_model import LogisticRegression, Ridge\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n"
      ],
      "metadata": {
        "id": "fpp-Bvc_k6fX"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Taking log as a global variable\n",
        "log = \"\"\n"
      ],
      "metadata": {
        "id": "5y1Q302Plfur"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Establishing directoyires to read original as well as incomplete datasets\n",
        "def read_subsets_and_original(BASE_PATH, ORIGINAL_BASE_PATH, dataset_name):\n",
        "  sub_incomplete_dataset = os.listdir(BASE_PATH + dataset_name)\n",
        "  print (\"Found Total Subsets : \", len(sub_incomplete_dataset))\n",
        "  original = pd.read_csv(ORIGINAL_BASE_PATH +'data12.csv', header=None)\n",
        "  original = original.infer_objects()\n",
        "  subsets = {}\n",
        "  for each in tqdm(sub_incomplete_dataset, total=len(sub_incomplete_dataset)):\n",
        "    subsets[each.split('.')[0]] = pd.read_csv(BASE_PATH + dataset_name + '/' + each, header=None)\n",
        "  return subsets, original\n"
      ],
      "metadata": {
        "id": "O0QlQ8cCl_mX"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculate NRMS value (Formula according to the documentation)\n",
        "def calculate_NRMS(y_true, y_pred):\n",
        "  upper_values = y_pred - y_true\n",
        "  #CHECK DOCUMENTATION ON https://numpy.org/doc/stable/reference/generated/numpy.linalg.norm.html\n",
        "\n",
        "  #ord = 'fro' means frobenius norm that is the euclidian distance\n",
        "  upper_normed = np.linalg.norm(upper_values, ord='fro')\n",
        "  lower_normed = np.linalg.norm(y_true, ord='fro')\n",
        "  return upper_normed / lower_normed"
      ],
      "metadata": {
        "id": "wiMHFp08mpp_"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.random.mtrand import shuffle\n",
        "#Build GRNN Model\n",
        "class GRNN(BaseEstimator, RegressorMixin):\n",
        "    #Initializing all the elements\n",
        "    def __init__(self, kernel='RBF', sigma=0.7, n_splits=5, calibration='warm_start', method='L-BFGS-B', bnds=(0, None), n_restarts_optimizer=0, seed = 42):\n",
        "        self.kernel = kernel\n",
        "        self.sigma = sigma\n",
        "        self.n_splits = n_splits\n",
        "        self.calibration = calibration\n",
        "        self.method = method\n",
        "        self.iterations = 0\n",
        "        self.bnds = bnds\n",
        "        self.n_restarts_optimizer = n_restarts_optimizer\n",
        "        self.seed = seed\n",
        "        \n",
        "    def fit(self, X, y):\n",
        "\n",
        "        # Check that X and y have correct shape\n",
        "        # X, y = check_X_y(X, y)\n",
        "        \n",
        "        self.X_ = X\n",
        "        self.y_ = y\n",
        "        bounds = self.bnds\n",
        "        \n",
        "        np.seterr(divide='ignore', invalid='ignore')\n",
        "         #Initializaing and establishing the cost function\n",
        "        def cost(sigma_):\n",
        "            kf = KFold(n_splits= self.n_splits)\n",
        "            kf.get_n_splits(self.X_)\n",
        "            cv_err = []\n",
        "            for train_index, validate_index in kf.split(self.X_):\n",
        "                X_tr, X_val = self.X_[train_index], self.X_[validate_index]\n",
        "                y_tr, y_val = self.y_[train_index], self.y_[validate_index]\n",
        "                Kernel_def_= getattr(kernels, self.kernel)(length_scale=sigma_)\n",
        "                K_ = Kernel_def_(X_tr, X_val)\n",
        "                # If the distances are very high/low, zero-densities must be prevented:\n",
        "                K_ = np.nan_to_num(K_)\n",
        "                psum_ = K_.sum(axis=0).T # Cumulate denominator of the Nadaraya-Watson estimator\n",
        "                psum_ = np.nan_to_num(psum_)\n",
        "                y_pred_ = (np.dot(y_tr.T, K_) / psum_)\n",
        "                y_pred_ = np.nan_to_num(y_pred_)\n",
        "                cv_err.append(MSE(y_val, y_pred_.T))\n",
        "                break\n",
        "            return cv_err[0] ## Mean error over the k splits                        \n",
        "        \n",
        "        #Establising the optimization function\n",
        "        def optimization(x0_):\n",
        "            rlog = \"\"\n",
        "            if len(self.bnds) > 1:\n",
        "              self.bnds = (self.bnds[0], )\n",
        "\n",
        "\n",
        "            try:\n",
        "              if len(x0_) > 1:\n",
        "                x0_ = x0_[0]\n",
        "            except:\n",
        "              rlog = \"x0_ is Good Enough\"\n",
        "               # print (\"x0_\", x0_)\n",
        "            # print (\"Bounds : \", self.bnds)\n",
        "            opt = optimize.minimize(cost, x0_, method=self.method, bounds=self.bnds)\n",
        "            if opt['success'] is True:\n",
        "                opt_sigma = opt['x']\n",
        "                opt_cv_error = opt['fun']\n",
        "            else:\n",
        "                opt_sigma = np.full(len(self.X_[0]), np.nan)\n",
        "                opt_cv_error = np.inf\n",
        "                pass\n",
        "            return [opt_sigma, opt_cv_error]\n",
        "        \n",
        "        #Regulating and calibrating sigma\n",
        "        def calibrate_sigma(self):\n",
        "            x0 = np.asarray(self.sigma) # Starting guess (either user-defined or measured with warm start)\n",
        "            if self.n_restarts_optimizer > 0:\n",
        "                # print (\"################################\")    \n",
        "                optima = [optimization(x0)]            \n",
        "                #First optimize starting from theta specified in kernel\n",
        "                optima = [optimization(x0)] \n",
        "                # # Additional runs are performed from log-uniform chosen initial bandwidths\n",
        "                r_s = np.random.RandomState(self.seed)\n",
        "                for iteration in range(self.n_restarts_optimizer): \n",
        "                    x0_iter = np.full(len(self.X_[0]), np.around(r_s.uniform(0,1), decimals=3))\n",
        "                    optima.append(optimization(x0_iter))             \n",
        "            elif self.n_restarts_optimizer == 0: \n",
        "                # print (\"Running SAD ONE\")    \n",
        "                optima = [optimization(x0)]            \n",
        "            else:\n",
        "                raise ValueError('n_restarts_optimizer must be a positive int!')\n",
        "            \n",
        "            # Select sigma from the run minimizing cost\n",
        "            cost_values = list(map(itemgetter(1), optima))\n",
        "            self.sigma = optima[np.argmin(cost_values)][0]\n",
        "            self.cv_error = np.min(cost_values) \n",
        "            return self\n",
        "        global log\n",
        "        if self.calibration is 'warm_start':\n",
        "            log = log + 'Executing warm start...' + '/n'\n",
        "            self.bnds = (bounds,)           \n",
        "            x0 = np.asarray(self.sigma)\n",
        "            optima = [optimization(x0)]            \n",
        "            cost_values = list(map(itemgetter(1), optima))\n",
        "            self.sigma = optima[np.argmin(cost_values)][0]\n",
        "            log = log + 'Warm start concluded. The optimum isotropic sigma is ' + str(self.sigma) + '/n'\n",
        "            self.sigma = np.full(len(self.X_[0]), np.around(self.sigma, decimals=3))\n",
        "            self.bnds = (bounds,)*len(self.X_[0])\n",
        "            # print ('Executing gradient search...')\n",
        "            calibrate_sigma(self)\n",
        "            log = log + 'Gradient search concluded. The optimum sigma is ' + str(self.sigma) + '/n'\n",
        "        elif self.calibration is 'gradient_search':\n",
        "            #print ('Executing gradient search...')\n",
        "            self.sigma = np.full(len(self.X_[0]), self.sigma)\n",
        "            self.bnds = (bounds,)*len(self.X_[0])\n",
        "            calibrate_sigma(self)\n",
        "            #print('Gradient search concluded. The optimum sigma is ' + str(self.sigma))\n",
        "        else:\n",
        "            pass\n",
        "                   \n",
        "        self.is_fitted_ = True\n",
        "        # Return the regressor\n",
        "        return self\n",
        "   #Gathering all the above and predicting the values \n",
        "    def predict(self, X):\n",
        "        \n",
        "         # Check if fit had been called\n",
        "        # check_is_fitted(self, ['X_', 'y_'])\n",
        "        \n",
        "        # Input validation\n",
        "        X = check_array(X)\n",
        "        \n",
        "        Kernel_def= getattr(kernels, self.kernel)(length_scale=self.sigma)\n",
        "        K = Kernel_def(self.X_, X)\n",
        "        # If the distances are very high/low, zero-densities must be prevented:\n",
        "        K = np.nan_to_num(K)\n",
        "        psum = K.sum(axis=0).T # Cumulate denominator of the Nadaraya-Watson estimator\n",
        "        psum = np.nan_to_num(psum)\n",
        "        return np.nan_to_num((np.dot(self.y_.T, K) / psum))\n"
      ],
      "metadata": {
        "id": "4z45VG7gnn5Y"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#saga feature selection\n",
        "def SAGA_FEATURE_SELECTION(X_train, y_train):\n",
        "  model_logistic = Ridge(solver='saga')\n",
        "  sel_model_logistic = SelectFromModel(estimator=model_logistic)\n",
        "  X_train_sfm_l1 = sel_model_logistic.fit_transform(X_train.values, y_train.values)\n",
        "  Indicator_columns = sel_model_logistic.get_support()\n",
        "  return Indicator_columns #SAGA BASED FEATURE SELECTION"
      ],
      "metadata": {
        "id": "R6fFffnyoREN"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Reading the data to run our model on\n",
        "BASE = 'gdrive/My Drive/'\n",
        "BASE_PATH = BASE + 'incomplete/'\n",
        "ORIGINAL_BASE_PATH = BASE + 'complete_dataset/'\n",
        "data = pd.read_excel(BASE + 'Table-NRMS.xlsx')\n",
        "#data = pd.read_csv(BASE + 'List.csv')\n"
      ],
      "metadata": {
        "id": "wfy5pJmgoZGv"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NRMS_DICT = {}\n"
      ],
      "metadata": {
        "id": "Jv5_Ztc_OAOP"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "begin_time = time.time()\n",
        "\n",
        "for index, row in tqdm(data.iterrows(), total=data.shape[0]): #For Dataset\n",
        "  subsets, original = read_subsets_and_original(BASE_PATH, ORIGINAL_BASE_PATH, row['Datasets']) # Get All Subsets and Original Dataset\n",
        "  subset_names = list(subsets.keys())\n",
        "  print(subset_names)\n",
        "  #ITERATE OVER ALL SUBSETS OF A DATASET AND APPLY GRNN ON EACH ONE\n",
        "\n",
        "  for each_subset_name in subset_names:\n",
        "\n",
        "    #SELECTING A SUBSET\n",
        "    selected_subset = subsets[each_subset_name]\n",
        "    #print(selected_subset)\n",
        "\n",
        "\n",
        "    new_prediction = np.zeros(shape=original.shape) #SAMPLE ARRAY TO SAVE PREDICTIONS\n",
        "    #print(new_prediction.shape)\n",
        "    #print(selected_subset.columns)\n",
        "    new_prediction = pd.DataFrame(data = new_prediction, columns=selected_subset.columns)\n",
        "\n",
        "\n",
        "\n",
        "    #COLUMNS ARRAY TO ITERATE\n",
        "    all_cols = np.array(original.columns) \n",
        "    for each in tqdm(all_cols, total=len(all_cols)):\n",
        "\n",
        "\n",
        "\n",
        "      #ONE COLUMN IN TEST AND OTHERS IN TRAINING\n",
        "      train_cols = all_cols[all_cols != each] \n",
        "      test_col = each\n",
        "\n",
        "      #CHECKING IF THERE ARE NULL VALUES IN OUR TEST COLUMNS\n",
        "      nulls = selected_subset[each].isnull() \n",
        "     \n",
        "      test_index = nulls[nulls == True].index\n",
        "      train_index = nulls[nulls == False].index\n",
        "    #  print(test_index.shape)\n",
        "      #print(test_index.shape[0] / float(nulls.shape[0]))\n",
        "\n",
        "\n",
        "\n",
        "      #IF THERE IS NO NULL VALUE THEN WE WONT APPLY GRNN\n",
        "      if test_index.shape[0] == 0:\n",
        "        new_prediction[each] = original[each].copy()\n",
        "    \n",
        "\n",
        "      else:\n",
        "\n",
        "        #TRAIN GRNN ON INDEX WHERE THERE IS NO NULL AND PREDICT ON NULL VALUES\n",
        "        custom_GRNN = GRNN()\n",
        "        #print('in grnn')\n",
        "        SAGA_BASED_FEATURES = SAGA_FEATURE_SELECTION(original[train_cols].loc[train_index], original[test_col].loc[train_index])\n",
        "        #print(SAGA_BASED_FEATURES) #SAGA\n",
        "    \n",
        "\n",
        "\n",
        "        #Normalization\n",
        "        normalizer = StandardScaler()\n",
        "\n",
        "        train_X = original[train_cols[SAGA_BASED_FEATURES]].loc[train_index].values\n",
        "        train_Y = original[test_col].loc[train_index].values\n",
        "       # print(train_X)\n",
        "        test_X = original[train_cols[SAGA_BASED_FEATURES]].loc[test_index].values\n",
        "        #print(train_X, train_Y)\n",
        "\n",
        "        normalizer.fit(train_X, train_Y)\n",
        "\n",
        "        normalizer_train_X = normalizer.transform(train_X)\n",
        "        normalizer_test_X = normalizer.transform(test_X)\n",
        "        ############################################\n",
        "        ############################################\n",
        "        \n",
        "\n",
        "\n",
        "        custom_GRNN.fit(normalizer_train_X, train_Y)\n",
        "        #PREDICT\n",
        "        prediction_smothened = custom_GRNN.predict(normalizer_test_X)\n",
        "        #print(prediction_smothened)\n",
        "\n",
        "        #FILL OUR SAVING ARRAY WITH PREDICTIONS\n",
        "        new_prediction[each].loc[train_index] = selected_subset[each].loc[train_index]\n",
        "        new_prediction[each].loc[test_index] = prediction_smothened\n",
        "       # print(each_subset_name)\n",
        "       # print(new_prediction)\n",
        "        new_prediction.to_csv(BASE + \"imputed_\" + each_subset_name + \".csv\", index=False)\n",
        "        NRMSE = calculate_NRMS(original.values, new_prediction.values)\n",
        "        print(NRMSE)\n",
        "        log = log + \"Done Smoothing of : \" + each_subset_name + \" with NRMS : \" + str(NRMSE) + '/n/n/n'\n",
        "        NRMS_DICT[each_subset_name] = NRMSE\n",
        "\n",
        "end_time = time.time()\n",
        "diff = end_time - begin_time\n",
        "print(diff)\n",
        "print(NRMS_DICT)\n",
        "#print(log)\n",
        "#df = pd.DataFrame(NRMS_DICT.values())\n",
        "value = pd.DataFrame.from_dict(NRMS_DICT, orient='index')\n",
        "#logs = log.split('/n')\n",
        "#for each in logs:\n",
        "#    x = each.split(' ')   \n",
        "#    if len(x) > 0:\n",
        "#        if x[0] == 'Done':\n",
        "##            df['NRMS'] = x[8]\n",
        " #           df['Datasets'] = x[4]\n",
        " #          print(x[8], x[4])#\n",
        "\n",
        "print(value)\n",
        "value.to_csv('Table.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FzkI8QNkRIi",
        "outputId": "e835fb94-da18-48ec-ddca-3568afdeb36c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/38 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found Total Subsets :  1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Data_12_AG_10%']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/51 [00:00<?, ?it/s]\u001b[A\n",
            "  2%|▏         | 1/51 [01:19<1:06:28, 79.76s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9962064525069462\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  4%|▍         | 2/51 [02:29<1:00:08, 73.65s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9927516946935744\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  6%|▌         | 3/51 [03:42<58:54, 73.63s/it]  \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9892970662926144\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  8%|▊         | 4/51 [04:54<57:01, 72.79s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.985499801405672\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 10%|▉         | 5/51 [06:06<55:33, 72.48s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.982067598119838\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 14%|█▎        | 7/51 [07:16<39:12, 53.46s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9748374684445172\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 16%|█▌        | 8/51 [09:01<48:08, 67.18s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9709674793053821\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 18%|█▊        | 9/51 [10:15<48:26, 69.21s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.967332605019645\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 20%|█▉        | 10/51 [12:05<55:06, 80.66s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9633560024306208\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 22%|██▏       | 11/51 [13:24<53:32, 80.31s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9596323404483786\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 24%|██▎       | 12/51 [15:44<1:03:19, 97.43s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9557773412917548\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 25%|██▌       | 13/51 [17:30<1:03:24, 100.11s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.951467769051495\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 29%|██▉       | 15/51 [18:48<43:18, 72.17s/it]   \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.943374213863127\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 31%|███▏      | 16/51 [20:36<47:18, 81.09s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9390939441153707\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 35%|███▌      | 18/51 [22:15<37:22, 67.96s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8642521575197007\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 37%|███▋      | 19/51 [23:58<40:29, 75.91s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7926963537712359\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 39%|███▉      | 20/51 [25:32<41:35, 80.49s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7879069938558851\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 41%|████      | 21/51 [26:50<39:54, 79.82s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7836881946879954\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 43%|████▎     | 22/51 [28:29<41:01, 84.87s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7791907862184076\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 45%|████▌     | 23/51 [30:26<43:45, 93.77s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7747733702810468\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 47%|████▋     | 24/51 [32:36<46:50, 104.11s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7697798731708003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 49%|████▉     | 25/51 [34:07<43:30, 100.42s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7648450555418388\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 51%|█████     | 26/51 [35:33<40:07, 96.31s/it] \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7601050225767478\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 53%|█████▎    | 27/51 [37:19<39:37, 99.08s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7546026189762047\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 55%|█████▍    | 28/51 [38:52<37:16, 97.26s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6718190844677029\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 57%|█████▋    | 29/51 [40:29<35:35, 97.08s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.666380832485477\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 59%|█████▉    | 30/51 [42:03<33:43, 96.36s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6602853279046967\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 61%|██████    | 31/51 [43:22<30:22, 91.13s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6550267467830225\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 63%|██████▎   | 32/51 [45:15<30:53, 97.55s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6492395071054988\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 65%|██████▍   | 33/51 [46:47<28:47, 95.96s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5447276495234605\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 67%|██████▋   | 34/51 [48:14<26:23, 93.15s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5380351589984463\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 69%|██████▊   | 35/51 [50:00<25:54, 97.17s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5311191897665728\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 71%|███████   | 36/51 [51:21<23:02, 92.14s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5236859161704415\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 73%|███████▎  | 37/51 [53:10<22:41, 97.22s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.516287204912546\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 75%|███████▍  | 38/51 [54:32<20:04, 92.63s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5089545438666783\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 76%|███████▋  | 39/51 [55:50<17:40, 88.36s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.3423120426335662\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 78%|███████▊  | 40/51 [57:32<16:57, 92.48s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.3325266683593524\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 80%|████████  | 41/51 [58:50<14:41, 88.10s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.32096304753397953\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 82%|████████▏ | 42/51 [59:58<12:20, 82.24s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.30936137852089013\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 84%|████████▍ | 43/51 [1:01:31<11:22, 85.29s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.29675570112718863\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 86%|████████▋ | 44/51 [1:02:47<09:38, 82.64s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.28421696312763917\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 88%|████████▊ | 45/51 [1:04:09<08:14, 82.35s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.2724596023593752\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 90%|█████████ | 46/51 [1:06:09<07:48, 93.78s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.2573781833581079\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 92%|█████████▏| 47/51 [1:07:25<05:53, 88.38s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.24411905602909345\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 94%|█████████▍| 48/51 [1:08:43<04:15, 85.30s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.22891271891249917\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 96%|█████████▌| 49/51 [1:10:23<02:58, 89.49s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.21142963324362768\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|██████████| 51/51 [1:11:48<00:00, 84.48s/it]\n",
            "  3%|▎         | 1/38 [1:11:50<44:17:53, 4310.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.1939019999046496\n",
            "Found Total Subsets :  1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Data_12_AG_20%']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/51 [00:00<?, ?it/s]\u001b[A"
          ]
        }
      ]
    }
  ]
}